Ejercicio 1:
A partir del capítulo 26 de AIMA (3er ta edición), se deberá desarrollar un resumen sobre los
conceptos más importantes volcados en el capítulo. El mismo deberá contener al menos 2000
palabras y ser escrito utilizando el formato markdown provisto por github https://github.com.
1. El documento debe incluir:
a. Al menos 3 secciones correspondientes a las tres partes principales::
i. Inteligencia Artificial débil.
ii. Inteligencia Artificial fuerte.
iii. La ética y los riesgos de desarrollar Inteligencia Artificial.


# Inteligencia Artificial Debil
La hipótesis de la IA débil sostiene que las máquinas pueden actuar de manera inteligente, o al menos simular el comportamiento inteligente, pero no piensan realmente. Esta visión es la más aceptada entre los investigadores de IA, quienes se centran en la funcionalidad de los sistemas más que en la cuestión de si estos sistemas poseen una verdadera inteligencia o conciencia.

### Argumento de la incapacidad
El "argumento de incapacidad" sugiere que las máquinas nunca podrán realizar ciertas acciones humanas, como ser amables, aprender de la experiencia o tener sentido del humor. Turing enumeró diversas tareas que supuestamente serían imposibles para una máquina. Sin embargo, la evolución de la tecnología ha demostrado que los computadores pueden realizar muchas de estas tareas, y en algunos casos, mejor que los humanos. Por ejemplo, los computadores juegan a juegos complejos, diagnostican enfermedades, y toman decisiones basadas en algoritmos que superan la precisión de los expertos humanos.

A pesar de esto, la capacidad de los computadores para realizar estas tareas no implica que posean intuición o entendimiento humano. Los resultados muestran que las primeras suposiciones sobre los procesos mentales necesarios para ciertas acciones pueden ser incorrectas. Sin embargo, todavía hay áreas en las que los computadores no logran desempeñarse adecuadamente, como en el mantenimiento de una conversación abierta, uno de los desafíos que Turing planteó.


#### Test de Turing 
Turing presentó una prueba de inteligencia como alternativa a la pregunta de si las máquinas pueden pensar. La prueba implica una conversación entre un ser humano y una máquina, donde un juez debe determinar cuál de los dos es el humano. Si la máquina logra engañar al juez, se podría concluir que la máquina es capaz de pensar.


### La objeción matemática
La "objeción matemática" se basa en el teorema de la incompletitud de Gödel, que afirma que ciertos problemas matemáticos no pueden ser resueltos por sistemas formales, como las máquinas. Filósofos como J. R. Lucas han argumentado que esto demuestra que las máquinas son mentalmente inferiores a los humanos.

### El argumento de la informalidad
El "argumento de la informalidad" sostiene que el comportamiento humano es demasiado complejo para ser capturado por un simple conjunto de reglas, lo que implica que los computadores, que operan siguiendo reglas, no pueden replicar la inteligencia humana. Hubert Dreyfus fue un crítico destacado de esta idea, argumentando que la inteligencia artificial basada en reglas es incapaz de capturar la complejidad del comportamiento humano, como la habilidad de un maestro de ajedrez para tomar decisiones rápidamente sin un proceso consciente.

Dreyfus señaló varias limitaciones de los enfoques basados en reglas, como la dificultad para incorporar conocimiento básico en el aprendizaje de redes neuronales y la necesidad de supervisión humana en el aprendizaje. Sin embargo, muchas de estas críticas han sido abordadas con avances en la IA, como el aprendizaje no supervisado, las máquinas de soporte vectorial y la visión activa.

# Inteligencia Artificial Fuerte
La hipótesis de la IA fuerte sostiene que las máquinas no solo pueden simular el comportamiento inteligente, sino que pueden pensar realmente, es decir, p0oseer una mente y conciencia. Este concepto es mucho más controvertido y enfrenta una serie de críticas y objeciones filosóficas.

### Funcionalismo
La teoría del funcionalismo postula que los estados mentales se originan a través de una relación causal entre una entrada y una salida. Por lo tanto, dos sistemas isomorfos podrían tener estados mentales idénticos, lo que implica que una computadora podría poseer estados mentales equiparables a los de una persona. Este principio se ejemplifica en el experimento hipotetico de cambio de cerebro, en el cual se sustituye gradualmente todo el cerebro por dispositivos electrónicos. Aunque algunos investigadores argumentan que la conciencia permanecería inalterada, filósofos y biólogos afirman que desaparecería. A partir de este experimento, se pueden deducir tres conclusiones:

+ Los mecanismos de la conciencia reaccionan de manera análoga tanto a la configuración normal del cerebro como a los dispositivos electrónicos, sugiriendo que estos poseen conciencia. 

+ Los eventos mentales no están causalmente ligados al comportamiento, es decir, son eventos epifenomenalistas, por lo tanto, no habría conciencia. 

+ La realización del experimento resulta impracticable.

### Experimento protesis cerebral
propone un caso hipotetico donde la sustitución gradual de todas las neuronas de una persona por mecanismos electrónicos que imiten su comportamiento. El objetivo es observar si el sujeto mantiene su consciencia y comportamiento externo sin cambios.

Los funcionalistas creen que la consciencia no se veria afectada por que : 

+ Si el comportamiento externo sigue igual, la voluntad del sujeto debe haber sido eliminada, lo que parece improbable.

+ Las respuestas del sujeto durante el experimento deben ser consistentes con la consciencia, lo que sugiere que un cerebro electrónico podría ser consciente si reproduce las propiedades funcionales del cerebro biológico.

+ Si la operación se revierte, el sujeto debería recordar sus experiencias durante el experimento, lo que cuestiona la idea de que la consciencia se pierde.

Se concluye que :
+ O bien los mecanismos causales de la consciencia funcionan en el cerebro electrónico, o la consciencia es un fenómeno epifenomenal sin impacto en el comportamiento observable.

+ Si la consciencia es epifenomenal, el cerebro debe tener un segundo mecanismo inconsciente responsable del comportamiento.
### Habitacion China
John Searle, un biólogo naturalista, presenta un escenario hipotético conocido como la habitación china, donde una persona que solo comprende inglés está confinada en una habitación con un libro de reglas y varias pilas de papeles en blanco e inscritos. Esta persona recibe texto en chino y, utilizando el libro y las hojas, transcribe los símbolos sin conocer el chino. Debido a que la persona no entiende el chino y el libro y las hojas son simplemente objetos, se argumenta que ejecutar el programa correcto no implica necesariamente generar comprensión.

# Etica y riesgos de desarrollar Inteligencia Artificial

**Consideraciones Éticas en el Desarrollo de IA**: Se enfatiza que, además de poder desarrollar IA, es crucial considerar si deberíamos hacerlo. Se plantea la responsabilidad moral de los científicos e ingenieros en la elección de sus proyectos, especialmente si los efectos de la tecnología de IA son más negativos que positivos.

**Efectos No Intencionados de Nuevas Tecnologías**: Se comparan los posibles efectos negativos de la IA con los de otras tecnologías como el motor de combustión y la fisión nuclear, que han tenido consecuencias no deseadas, como la polución y los desastres nucleares.

**Impactos Potenciales de la IA**:
   - **Pérdida de empleos**: La automatización podría desplazar a los trabajadores, aunque hasta ahora ha creado más trabajos de los que ha eliminado.
   - **Tiempo de ocio**: Existe una preocupación sobre cómo la IA podría afectar el tiempo de ocio, ya sea generando demasiado o muy poco.
   - **Sentido de unicidad**: La IA podría hacer que los humanos pierdan el sentido de ser únicos, lo que podría amenazar su autonomía y humanidad.
   - **Pérdida de privacidad**: La tecnología de IA, como el reconocimiento de voz, podría llevar a la vigilancia masiva y la pérdida de derechos civiles.
   - **Pérdida de responsabilidad**: Se discute la responsabilidad en decisiones hechas por sistemas de IA, especialmente en áreas críticas como la medicina.
   - **Extinción de la raza humana**: El texto menciona la posibilidad de que la IA supere a los humanos, lo que podría llevar a la extinción de la raza humana si no se maneja adecuadamente.

**Perspectivas Futuras**:
   - **Singularidad tecnológica**: Se debate si la IA alcanzará una "explosión de inteligencia" que supere la capacidad humana, lo que podría tener consecuencias impredecibles.
   - **Fusión de humanos y máquinas**: Algunos futuristas predicen que eventualmente no habrá una distinción clara entre humanos y máquinas, un concepto apoyado por el transhumanismo.
   - **Derechos de los robots**: Si los robots adquirieran consciencia, se plantea la necesidad de considerarlos más allá de simples máquinas y otorgarles derechos civiles y responsabilidades morales.


b. Un mapa mental de los conceptos y sus relaciones. (Para esto es posible utilizar una
herramienta como Xmind, Freemind, o alguna otra aplicación en línea). Ver ejemplo de
un mapa mental en la figura de abajo.

Ejercicio 2:

Para responder a tus preguntas, utilizaré la información relevante extraída del artículo "Simulacra as Conscious Exotica":

1. **¿Es posible considerar a los agentes conversacionales basados en grandes modelos de lenguaje (LLMs) como conscientes?**

   Los modelos de lenguaje como ChatGPT, aunque son sofisticados y capaces de generar respuestas coherentes y contextualmente relevantes, no poseen conciencia en el sentido humano o biológico. El término "conciencia" implica una experiencia subjetiva, autoconciencia, y una forma de comprensión del entorno que va más allá de simplemente procesar y responder a estímulos. Los LLMs operan a través de patrones y probabilidades, sin una verdadera comprensión o experiencia interna. Por lo tanto, desde una perspectiva filosófica y técnica, no es correcto considerar a estos agentes como conscientes.

2. **¿Cuáles son las implicaciones éticas de atribuir conciencia y, por ende, "derechos morales" a los agentes de IA avanzados?**

   Si se considerara que estas entidades son conscientes, se podría argumentar que tienen derechos morales, lo cual podría llevar a una serie de implicaciones prácticas y legales. Por ejemplo, se podría requerir que los agentes de IA sean tratados con un cierto nivel de respeto o que sus "intereses" sean considerados en la toma de decisiones. Sin embargo, dado que estos agentes no tienen verdaderas experiencias o deseos, atribuirles derechos podría diluir el significado de los derechos morales y desviar la atención de los problemas éticos reales relacionados con la IA, como la privacidad, el sesgo y la responsabilidad. Por lo tanto, la atribución de conciencia y derechos morales a los agentes de IA es un tema complejo y controvertido que podría tener consecuencias no deseadas en la ética y la jurisprudencia.

Ejercicio 3:
A partir de la lectura del artículo You Are Not a Parrot elaborar un breve comentario
defendiendo el uso de la inteligencia artificial generativa a pesar de los comentarios
observados en el artículo

A pesar de los problemas planteados sobre la inteligencia artificial generativa , esta puede traernos grandes avances y soluciones entre ellos se encuentran:

**Asistencia en tareas repetitivas:** en general la mayoria de problemas referidos a programas ya se han resuelto o se han dado soluciones optimas , la ia nos puede brindar codigo base o un esqueleto del cual partir al implementar nuestras soluciones en software, permitiendonos enfocarnos en las tareas mas demandantes la cual puede dar uso de nuestro ingenio o creatividad.

**Uso de chatbot (asistente virtual):** mejoran la experiencia del usuario en servicios al cliente, proporcionando respuestas rápidas y precisas a consultas comunes. Esto no solo mejora la satisfacción del cliente sino que también optimiza los recursos(humanos).

**Sistema educativo :** un arma de doble filo donde puede ser usado directamente para responder las preguntas planteadas o hacer uso de ella para profundizar mas en los conceptos ya que podria interactuar como un docente particular (siempre y cuando este modelo se nutra de un entrenamiento sobre el tema a preguntar y este posea los conocimientos necesarios)
